# Deep Perception


*Environment perception using deep learning techniques*

## Repository structure

    |_ data
    |  |_ images
    |  |  |_ training
    |  |     |_ image_2 // KITTI train images are here
    |  |  |_ testing
    |  |     |_ image_2 // KITTI Test images are here
    |  |__labels
          |_ labels_2 // KITTI Training labels           are here
    |_ lib // External code is here


## Todo
* *Download dataset* 
* Load the data into our current model
* Listen to YT lectures and read into papers to get a more profund idea of the layers of a convolutional network
* Define first model for dataset
* 

## Ideas

- Downscale images before training

## Questions
- How do conv nets correctly handle input images of different sizes? What is the best way for downsampled images? Can we feed conv nets different sizes
- More Ressources what the single layers in a conv network are actually doing.


## Links
* [ML Homepage](http://lmb.informatik.uni-freiburg.de/lectures/computer_vision_I/)
* [Task Instructions](http://ml.informatik.uni-freiburg.de/_media/teaching/ws1314/dl/10-working_phase_3.pdf)
* [Data Set](http://www.cvlibs.net/datasets/kitti/eval_object.php)


